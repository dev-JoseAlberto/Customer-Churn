---
title: "Customer Churn Prediction"
author: "Jose Alberto"
date: "08/06/2021"
output: github_document
---

```{r}
rm(list=ls(all=TRUE))
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


Customer Churn

A churn is when a customer stops paying or subscribing to your products or  services.
In other word, is the loss these customers.

Customer churn is one of the most important business metrics.

Thatâ€™s because the cost of retaining an existing customer is significantly less than the cost of acquiring a new one.

The latter is often referred to as Customer Acquisition Cost (CAC).

Companies use it as a metric to track if a company has a viable business model that can keep profits generating while maintaining a low CAC.

Load R Packages: 

```{r}
library(rmarkdown)
library(htmltools)
library(tidyverse)
library(dplyr)#dplyr is a grammar of data manipulation
library(lattice)
library(survival)
library(Formula)
library(missForest)
library(MLmetrics)
library(kernlab)
library(gridExtra)
library(caTools)#For Logistic regression
library(Amelia)#Amelia II is an R package for the multiple imputation of multivariate incomplete data
library(Hmisc)#imputing missing values
library(dlookr)#Tools for Data Diagnosis, Exploration, Transformation
library(rcompanion)#Functions to Support Extension Education Program Evaluation
library(PerformanceAnalytics)#Econometric Tools for Performance and Risk Analysis
library(corrplot)
library(lubridate)#Make Dealing with Dates a Little Easier
library(fpp)#Data for Forecasting
library(caret)#Classification and Regression Training        
library(caretEnsemble)#Ensembles of Caret Models
library(e1071)#Misc Functions of the Department of Statistics
library(plyr)#Tools for Splitting, Aplitting and Combining Data
library(randomForest)#Random Forest for Classification 
library(ROCR)
```


```{r pressure, echo=FALSE}
training_dataset <- read.csv("datasets/ml_case_training_data.csv", encoding='UTF-8', header = TRUE, na.strings = "")
```

```{r pressure, echo=FALSE}
history_dataset <- read.csv("datasets/ml_case_training_hist_data.csv", encoding='UTF-8', header = TRUE, na.strings = "")
```

```{r pressure, echo=FALSE}
churn_dataset <- read.csv("datasets/ml_case_training_output.csv", encoding='UTF-8', header=TRUE, na.strings = "")
```


```{r}
View(training_dataset)
```



```{r}
training_dataset2 <- training_dataset
```


```{r}
history_dataset2 <- history_dataset
```


```{r}
dim(training_dataset2)
```

```{r}
dim(history_dataset)
```

```{r}
dim(churn_dataset)
```

```{r}
str(training_dataset2)
```


```{r}
str(history_dataset2)
```


```{r}
str(churn_dataset)
```


## Using sapply on columns with missing values:
```{r}
sapply(training_dataset2, function(x) sum(is.na(x)))
```

```{r}
sapply(history_dataset2, function(x) sum(is.na(x)))
```

Compute the total missing values in each columns:

```{r}
colSums(is.na(churn_dataset))
```



### Plot a missinggness map showing where occurs in the dataset:

```{r}
missmap(training_dataset2, 
        legend=TRUE,
        col=c('#ff5c33', '#3399ff'),
        y.cex = 0.5,
        x.cex = 0.5
)
```


That finds duplicate values in a dataset:

```{r}
anyDuplicated(training_dataset)
```

```{r}
anyDuplicated(history_dataset)
```


```{r}
anyDuplicated(churn_dataset)
```


```{r}
summary(training_dataset[,c(5,6,7,13,14,15,16,17,18,19,20,21,22,23)])
```


```{r}
hist(na.pass(training_dataset$forecast_base_bill_ele), 
     col = 'blue',
     xlab = 'forecast_base_bill_ele',
     main = 'Distribution Variable Values of the Forecast Base Bill Ele')
```


```{r}
layout(matrix(c(1,2), nrow=1, ncol=2))
boxplot(training_dataset[training_dataset$forecast_bill_12m>=1,15], main = 'Forecast Bill 12m',pch=16, col = '#99ccff', border = '#00264d')
boxplot(training_dataset[training_dataset$forecast_price_energy_p1!=0,16], main = 'Forecast Price Energy p1',pch=16, col = '#99ffcc', border = '#00264d')
```


```{r}
layout(matrix(c(1,2), nrow=1, ncol=2))
plot_outlier(training_dataset[5])
```

```{r}
layout(matrix(c(1,2), nrow=2, ncol=2))
plot_normality(training_dataset[13])
```



##### Data Cleaning

Impute missing values to 0 in columns activity_new,campaign_disc_ele, channel_sales :


```{r}
training_dataset2[is.na(training_dataset2$activity_new),]$activity_new <- 0
```



```{r}
training_dataset2[is.na(training_dataset2$campaign_disc_ele),]$campaign_disc_ele <- 0
```


```{r}
training_dataset2[is.na(training_dataset2$channel_sales),]$channel_sales <- 0
```


```{r}
training_dataset2[is.na(training_dataset2$origin_up),]$origin_up <- 0
```



 Using impute function from Hmisc package replace with median the columns:
 
```{r}
training_dataset2$forecast_base_bill_ele <- Hmisc::impute(training_dataset2$forecast_base_bill_ele, median)
```


```{r}
training_dataset2$forecast_base_bill_year <- Hmisc::impute(training_dataset2$forecast_base_bill_year, median)
```


```{r}
training_dataset2$forecast_bill_12m <- Hmisc::impute(training_dataset2$forecast_bill_12m, median)
```


```{r}
training_dataset2$forecast_cons <- Hmisc::impute(training_dataset2$forecast_cons, median)
```


```{r}
training_dataset2$forecast_discount_energy  <- Hmisc::impute(training_dataset2$forecast_discount_energy, median)
```


```{r}
training_dataset2$forecast_price_pow_p1  <- Hmisc::impute(training_dataset2$forecast_price_pow_p1, median)
```


```{r}
training_dataset2$forecast_price_energy_p1  <- Hmisc::impute(training_dataset2$forecast_price_energy_p1, median)
```


```{r}
training_dataset2$forecast_price_energy_p2  <- Hmisc::impute(training_dataset2$forecast_price_energy_p2, median)
```


```{r}
training_dataset2$margin_gross_pow_ele <- Hmisc::impute(training_dataset2$margin_gross_pow_ele, median)
```


```{r}
training_dataset2$margin_net_pow_ele <- Hmisc::impute(training_dataset2$margin_net_pow_ele, median)
```


```{r}
training_dataset2$net_margin <- Hmisc::impute(training_dataset2$net_margin, median)
```


```{r}
training_dataset2$pow_max <- Hmisc::impute(training_dataset2$pow_max, median)
```



```{r}
history_dataset2$price_p1_var <-  Hmisc::impute(history_dataset2$price_p1_var, median)
```



```{r}
history_dataset2$price_p2_var <-  Hmisc::impute(history_dataset2$price_p2_var, median)
```


```{r}
history_dataset2$price_p3_var <-  Hmisc::impute(history_dataset2$price_p3_var, median)
```


```{r}
history_dataset2$price_p1_fix <-  Hmisc::impute(history_dataset2$price_p1_fix, median)
```


```{r}
history_dataset2$price_p2_fix <-  Hmisc::impute(history_dataset2$price_p2_fix, median)
```


```{r}
history_dataset2$price_p3_fix <-  Hmisc::impute(history_dataset2$price_p3_fix, median)
```



###### The three forms of correlation presented here are Pearson, Kendall, and Spearman. 

Kendall and Spearman correlation use nonparametric tests. 

The test determining the p-value for Pearson correlation is a parametric test that assumes that data are bivariate normal.


```{r}
correlations_training_dataset2 <- cor(training_dataset2[,c(5,6,7,13,14,15,16,17,18,19,20,21)], method = "spearman")
```


```{r}
corrplot(correlations_training_dataset2, method="circle", type = "full")
```


```{r}
training_dataset2$has_gas <- mapvalues(training_dataset2$has_gas, from = c("f", "t"), to = c("FALSE", "TRUE"))
```


```{r}
training_dataset2$has_gas <- as.logical(training_dataset2$has_gas)
```


Coverting Strings to Date:
```{r}
training_dataset2$date_activ <- as.Date(training_dataset2$date_activ)
```


```{r}
training_dataset2$date_end <- as.Date(training_dataset2$date_end)
```


```{r}
training_dataset2$date_first_activ <- as.Date(training_dataset2$date_first_activ, format="%Y-%m-%d")
```


```{r}
training_dataset2$date_modif_prod <- as.Date(training_dataset2$date_modif_prod)
```


```{r}
training_dataset2$date_renewal <- as.Date(training_dataset2$date_renewal)
```


```{r}
history_dataset2$price_date <- as.Date(history_dataset2$price_date)
```


Forecasting Times Series :

```{r}
ts_forecast_base_bill_year <- ts(unique(training_dataset2$forecast_base_bill_year), start=c(1970,1), end = c(2021,12),frequency=12)
```


```{r}
ts.plot(ts_forecast_base_bill_year, 
     col="#004080", 
     xlab="Year",
     ylab="Electricity Bill Baseline")
```

```{r}
seasonplot(ts1,col=rainbow(5))
```
```{r}
ts_forecast_base_bill_year_decompose <- decompose(ts_forecast_base_bill_year, "multiplicative")
```

```{r}
plot(ts_forecast_base_bill_year_decompose, col="#ff9900")
```

Feature engineering

Decompose the date 

Isolating components of the date

```{r}
training_dataset2["Year_activation_contract"] <- year(training_dataset2$date_activ)

training_dataset2["Month_activation_contract"] <- month(training_dataset2$date_activ)

training_dataset2["Day_Month_activation_contract"] <- day(training_dataset2$date_activ)
```

```{r}
training_dataset2["Year_of_the_End_contract"] <- year(training_dataset2$date_end)

training_dataset2["Month_of_the_End_contract"] <- month(training_dataset2$date_end)

training_dataset2["Day_Month_of_the_End_contract"] <- day(training_dataset2$date_end)
```

```{r}
training_dataset2["Year_of_first_contract"] <- year(training_dataset2$date_first_activ)

training_dataset2["Month_of_first_contract"] <- month(training_dataset2$date_first_activ)

training_dataset2["Day_Month_of_first_contract"] <- day(training_dataset2$date_first_activ)
```

```{r}
training_dataset2["Year_of_last_modification"] <- year(training_dataset2$date_modif_prod)

training_dataset2["Month_of_last_modification"] <- month(training_dataset2$date_modif_prod)

training_dataset2["Day_Month_of_last_modification"] <- day(training_dataset2$date_modif_prod)
```


```{r}
training_dataset2["Year_contract_renewal"] <- year(training_dataset2$date_renewal)

training_dataset2["Month_contract_renewal"] <- month(training_dataset2$date_renewal)

training_dataset2["Day_Month_contract_renewal"] <- day(training_dataset2$date_renewal)
```

```{r}
history_dataset2["Price_Year"] <- year(history_dataset2$price_date)

history_dataset2["Price_Month"] <- month(history_dataset2$price_date)

history_dataset2["Price_Day_Month"] <- day(history_dataset2$price_date)
```

Merge data frames

```{r}
dataset_merge <- merge(training_dataset2, history_dataset2, all=TRUE)
```


```{r}
dataset2_merge <- merge(dataset_merge, churn_dataset, all=TRUE)
```

```{r}
dataset3_merge <- dataset2_merge %>% 
        select(-one_of("id","activity_new","campaign_disc_ele",
                     "channel_sales","date_activ","date_end","date_first_activ",
                     "date_modif_prod","date_renewal","price_date","origin_up"))
```



```{r}
dim(dataset3_merge)
```

Removing rows with missing values:

```{r}
dataset3_merge <- na.omit(dataset3_merge)
```


Modeling & Evaluation
Customer Churn Prediction Model Binary Classification with Random Forest

```{r}
dataset3_merge$churn <- factor(dataset3_merge$churn, levels = c(1, 0), labels = c("Yes","No"))
table(dataset3_merge$churn)
```

```{r}
barplot(table(dataset3_merge$churn),  col = c('#0033cc','#ff0000'), main="Imbalanced Classes")
```


Partitioning the DataSet in Train and Test Set:

```{r}
partitionDataset <- createDataPartition(dataset3_merge$churn, 
                                        p=0.7, 
                                        list = FALSE)
```


```{r}
train_dataset <- dataset3_merge[partitionDataset,]
```


```{r}
train_dataset_balanced <- upSample(x = train_dataset [, -ncol(train_dataset)], y = train_dataset$churn)
```
 
```{r}
barplot(table(train_dataset_balanced$Class),  col = c('#0033cc','#ff0000'), main="Balanced Classes")
```

```{r}
test_dataset <- dataset3_merge[-partitionDataset,]
```


```{r}
test_dataset_balanced <- upSample(x = test_dataset[, -ncol(test_dataset)], 
                                    y = test_dataset$churn)
```


```{r}
model_rf <-  train(Class~cons_12m + 
                        cons_gas_12m+cons_last_month+
                        forecast_base_bill_ele+forecast_cons+
                        forecast_cons_12m+forecast_meter_rent_12m+
                        forecast_price_energy_p2+margin_gross_pow_ele+
                        net_margin+ pow_max+Year_of_first_contract+
                        Month_of_first_contract+Year_of_last_modification+
                        Day_Month_of_the_End_contract+
                        Day_Month_activation_contract+ 
                        Day_Month_of_first_contract+                      
                        Day_Month_contract_renewal,
                        method="rf",
                        data= train_dataset_balanced)
```


Random Forest is One of Several Different Classifiers That Provides Metric Variable Importance :

```{r}
varimp_model_rf <- varImp(model_rf, scale=FALSE)
```


```{r}
print(varimp_model_rf)
```



Customers to Churn Predictive Model Variables Importance Computes the Random Forest:

```{r}
plot1 <- plot(varimp_model_rf ,top=18, scales=list(y=list(cex=.95)), 
     main="Importance Computes the Random Forest")
```


```{r}
fit <- predict(model_rf,test_dataset_balanced)
```


```{r}
confusionMatrix(reference=test_dataset_balanced$Class, data=fit, mode="everything", positive="Yes")v
```


```{r}
treinoControle <-  trainControl(
        method = 'repeatedcv',
        number = 10,
        repeats = 2,
        search ='grid',
        savePredictions = 'final',
        summaryFunction = twoClassSummary,
        classProbs = TRUE)
```




```{r}
set.seed(123)
model2_rf <- train(Class~ margin_gross_pow_ele+cons_12m+
                  net_margin+forecast_cons_12m+
                 cons_last_month+
                  pow_max+Day_Month_activation_contract+
                  Day_Month_contract_renewal+
                  forecast_price_energy_p2+Year_of_last_modification+
                  cons_gas_12m+Year_of_first_contract+cons_gas_12m+
                  Month_of_first_contract+Day_Month_of_first_contract,
                  method ='rf',
                  tuneLength = 10,
                  trControl = treinoControle,
                  metric = 'ROC',
                  data = train_dataset_balanced)
```



```{r}
predict1 <- predict(model2_rf, newdata= test_dataset_balanced)
```


```{r}
confusionMatrix(reference =test_dataset_balanced$Class, data = predict1 , mode='everything', positive="Yes")
```


```{r}
fitProb <- predict(model2_rf, test_dataset_balanced, type='prob')
```


```{r}
alteredProb <- fitProb$`No`

```


```{r}
alteredProb <- factor(ifelse(alteredProb > 0.5, 'No','Yes'))
```


```{r}
confusionMatrix(reference= factor(test_dataset_balanced$Class, levels=c('No','Yes')), data=alteredProb, mode='everything', positive='Yes')
```

```{r}
predictions <- fitProb$Yes
```

```{r}
labels <- test_dataset_balanced$Class
```

```{r}
pred <- prediction(predictions, labels)
pred
```

```{r}
performance1 <- performance(pred,'tpr','fpr')
```

Receiver Operating Characteristic Curve: 

An ROC curve is a graph showing the performance of a classification model at all classification thresholds. 
This curve plots two parameters:

True Positive Rate
False Positive Rate
True Positive Rate (TPR) is a synonym for recall and is therefore defined as follows: TPR = TP/TP+FN

False Positive Rate (FPR) is defined as follows: FPR = FP/FP+TN

TP vs. FP rate at different classification thresholds.

An ROC curve plots TPR vs. FPR at different classification thresholds. 
Lowering the classification threshold classifies more items as positive, thus increasing both False Positives and True Positives. 
The following figure shows a ROC curve:


```{r}
plot(performance1, avg='threshold', colorize=TRUE)
```
